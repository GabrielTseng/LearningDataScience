{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Preprocess data from the [Physio Net 2012 challenge](https://physionet.org/challenge/2012/). The `PhysioNetDataset` can be used as a normal Pytorch Dataset, but because processing takes around 1 second per example, its more efficient to create the entire tensor using `preprocess_all()`, and save the entire array (especially because `preprocess_all()` takes advantage of multiprocessing. This is what happens here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import PhysioNetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PhysioNetDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 records\n",
      "Processed 200 records\n",
      "Processed 300 records\n",
      "Processed 400 records\n",
      "Processed 500 records\n",
      "Processed 600 records\n",
      "Processed 700 records\n",
      "Processed 800 records\n",
      "Processed 900 records\n",
      "Processed 1000 records\n",
      "Processed 1100 records\n",
      "Processed 1200 records\n",
      "Processed 1300 records\n",
      "Processed 1400 records\n",
      "Processed 1500 records\n",
      "Processed 1600 records\n",
      "Processed 1700 records\n",
      "Processed 1800 records\n",
      "Processed 1900 records\n",
      "Processed 2000 records\n",
      "Processed 2100 records\n",
      "Processed 2200 records\n",
      "Processed 2300 records\n",
      "Processed 2400 records\n",
      "Processed 2500 records\n",
      "Processed 2600 records\n",
      "Processed 2700 records\n",
      "Processed 2800 records\n",
      "Processed 2900 records\n",
      "Processed 3000 records\n",
      "Processed 3100 records\n",
      "Processed 3200 records\n",
      "Processed 3300 records\n",
      "Processed 3400 records\n",
      "Processed 3500 records\n",
      "Processed 3600 records\n",
      "Processed 3700 records\n",
      "Processed 3800 records\n",
      "Processed 3900 records\n",
      "Processed 4000 records\n"
     ]
    }
   ],
   "source": [
    "input_array, outcomes = dataset.preprocess_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4000, 48, 37]), torch.Size([4000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape, outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('physio_input.npy', input_array.numpy())\n",
    "np.save('physio_outcomes.npy', outcomes.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a `normalizing_dict` maps the features to their indices in the array. The features' means and standard deviations are also in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizing_dict = dataset.get_normalizing_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('physio_normalizing_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(normalizing_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
