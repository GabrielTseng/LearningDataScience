{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Insults in Social Commentary\n",
    "\n",
    "Because this dataset is far too small to use a neural network (which was my last approach to NLP), I'm going to experiment with some machine learning algorithms from scikit-learn to identify insults in social commentary.\n",
    "\n",
    "When this competition ran on Kaggle 5 years ago, the best AUC ROC score was 0.84249 on the private test set (which I also have access to, and will be using as my test set). Let's see if, using all of the new tools available (i.e. GloVe vectrs), I can better this score.\n",
    "\n",
    "## Making GloVe vectors\n",
    "\n",
    "In this notebook, I make an array of GloVe vectors, which I can then use to test a variety of different machine learning algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spacy \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3947"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv', encoding= 'utf8')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have 3947 comments to train a classifier with (for comparison, when training my Quora Neural Network, I had over 150,000 question pairs). \n",
    "\n",
    "Let's first check the distribution of insults: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1049 insults \n",
      "There are 2898 non insults\n"
     ]
    }
   ],
   "source": [
    "num_insults = len(data[data.Insult ==1])\n",
    "num_non_insults = len(data[data.Insult == 0])\n",
    "\n",
    "print (\"There are \" + str(num_insults) + \" insults \\nThere are \" + str(num_non_insults) + \" non insults\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is some skew to the data to bear in mind. \n",
    "\n",
    "There's some easy cleaning I can do to begin with, for instance removing the quotation marks around the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"stripped_comment\"] = data.Comment.apply(lambda x: re.sub('[^A-Za-z ]+', ' ',x[1:-1].replace('\\\\n', ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>stripped_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>You fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "      <td>i really don t understand your point xa  It se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "      <td>A xc xa majority of Canadians can and has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "      <td>listen if you dont wanna get married to a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "      <td>C xe c b u ea n xu u ed ng  u u b u eddng bi u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment  \\\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"   \n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...   \n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...   \n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...   \n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...   \n",
       "\n",
       "                                    stripped_comment  \n",
       "0                                 You fuck your dad   \n",
       "1  i really don t understand your point xa  It se...  \n",
       "2  A xc xa majority of Canadians can and has been...  \n",
       "3  listen if you dont wanna get married to a man ...  \n",
       "4  C xe c b u ea n xu u ed ng  u u b u eddng bi u...  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract more features, I'm going to use SpaCy, which will allow me to Tokenize and generally augment the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacy_comments = []\n",
    "\n",
    "for doc in nlp.pipe(data.stripped_comment, n_threads = -1):\n",
    "    spacy_comments.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've already explored briefly what SpaCy is capable of in [this notebook](https://github.com/GabrielTseng/LearningDataScience/blob/master/Natural_Language_Processing/Spacy_NLP.ipynb), so even though *apparently* little has changed, there is plenty of new information under the hood contained in that sentence. \n",
    "\n",
    "The most powerful of these are the [GloVe](https://nlp.stanford.edu/projects/glove/) word vectors, which are now part of every token - 'word' - in each SpaCy comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token 'Either' has a vector of shape (300,)\n"
     ]
    }
   ],
   "source": [
    "print (\"The token '\" + str(spacy_comments[8][0]) + \"' has a vector of shape \" + str(spacy_comments[8][0].vector.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(So does every other token). \n",
    "\n",
    "One challenge currently is that every comment has a different length. My solution to deal with this is different from with the Quora dataset. \n",
    "\n",
    "Given that each word vector has length 300, even truncating the dataset at some length would yield an x*300 matrix. Considering I only have ~4000 training datapoints, any value of x will very quickly lend itself to overfitting. \n",
    "\n",
    "Therefore, I am going to take the *average* of the word vectors instead, so that each comment is represented by a 300 length vector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment_array = []\n",
    "for x in spacy_comments[1]:\n",
    "    comment_array.append(x.vector.flatten())\n",
    "comment_array = np.mean(comment_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(comment_array).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. I just need to do this for every single comment. \n",
    "\n",
    "Since I'm averaging, I am going to remove stop words, which are unlikely to contribute to the 'sentiment' of the sentence, but may dilute the average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "How is defending your child vigilante justice?  Why are you defending a child rapist?\\xa0 Are you a closet pedo?"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_comments[3365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3947/3947 [00:07<00:00, 525.06it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_comments = []\n",
    "for i in tqdm(spacy_comments):\n",
    "    comment_array = [np.zeros(300)]\n",
    "    for x in i:\n",
    "        if ((x.vector == np.zeros(300)).all() == False): #and (x.is_stop == False)) :\n",
    "            comment_array.append(x.vector)\n",
    "    comment_array = np.mean(comment_array, axis = 0)\n",
    "    glove_comments.append(np.asarray(comment_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3947, 300)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_comments = np.asarray(glove_comments)\n",
    "glove_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. Now, I'm going to save this array for use with other algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('glove_array.npy', glove_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
